{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vodafone Challenge\n",
    "## Scrap notebook\n",
    "- **Separate each test** you make with a markdown cell like this one (press M when the cursor is on a cell but it is not editing). \n",
    "- Put a **small description** on what you are doing and why you do so (like if you manipulate data in a specific way, or apply a particular definition of distance, write the intuition behind. Both for you to remmember later and for team members)\n",
    "- Make sure you are working with the **proper data** i.e. the data (and their transformation) that you with to use are defined before you do the analysis. Bugs could appear if you do not define something and Python retrieves older values for the variables you are using.\n",
    "- **Do not modify df_backup**, always work with a copy [like df = df_backup.copy()]\n",
    "- Add short line of description in the Summary section\n",
    "- For each test, write briefly which value of the parameter tried (like learning rate constant, tried eta0 large (10^-2) not well, smaller (10^-7) seem to work best. Then changed with learning rate adaptivive [which?] and tried ... large (10^-2) worked best).\n",
    "\n",
    "**For the best test, build pipeline: bulleted version of all things done on the dataset until the result. It could be a useful thing to do for each test actually**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1. **K-means on traffic data**: description of the test (briefly, just to quickly know what tryed already)\n",
    "2. **Sample 2**: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "### *setup*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_backup = pd.read_csv('dataset_challenge_v5.TRAINING.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baldassi's Cleaning\n",
    "**DeviceOperatingSystem**: I preferred not to create a specific category for 'windows' because too few observations, however, if the 'other' category reveals to explain well, we can unpack it (in a new dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'iOS': 568, nan: 548, 'Android': 858, 'Windows Mobile': 6, 'Proprietary': 5, 'Windows Phone': 7, 'BlackBerry OS': 1, 'Firefox': 1, 'Symbian^3': 1, 'BREW': 1, 'Series 40': 2, 'BB10': 1, 'VRTXmc': 1}\n"
     ]
    }
   ],
   "source": [
    "df_clean = df_backup.copy()\n",
    "\n",
    "del df_clean['Unnamed: 0']\n",
    "\n",
    "c = list(df_clean.columns)\n",
    "c[0] = 'ID'\n",
    "df_clean.columns = c\n",
    "\n",
    "df_clean['ZipCode'] = df_clean['ZipCode'].map(lambda x: '%05i' % x, na_action='ignore')\n",
    "\n",
    "traffic_columns = ['File-Transfer', 'Games',\n",
    "       'Instant-Messaging-Applications', 'Mail', 'Music-Streaming',\n",
    "       'Network-Operation', 'P2P-Applications', 'Security',\n",
    "       'Streaming-Applications', 'Terminals', 'Unclassified', 'VoIP',\n",
    "       'Web-Applications']\n",
    "df_clean[traffic_columns]\n",
    "\n",
    "cats = df_clean['CustomerAge'].astype('category').cat.categories\n",
    "d = {cat:(15+10*i)/100 for i,cat in enumerate(cats)}\n",
    "df_clean['NumericAge'] = df_clean['CustomerAge'].map(lambda x: d[x], na_action='ignore')\n",
    "\n",
    "d = {}\n",
    "for elem in df_clean['DeviceOperatingSystem']:\n",
    "    d[elem] = d.get(elem, 0) + 1\n",
    "print(d) #some categories have very few values, group them\n",
    "OS_other = []\n",
    "for key in d:\n",
    "    if d[key] < 10:\n",
    "        OS_other.append(key)\n",
    "        d[key] = 'other'\n",
    "    else:\n",
    "        d[key] = key\n",
    "df_clean['OS_clean'] = df_clean['DeviceOperatingSystem'].map(lambda x: d[x], na_action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class definition and useful dependencies\n",
    "Space that collects classes or function definition that come in handy throughtout the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class buildTrain():\n",
    "    def __init__(self, X, y, perc=0.8, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        n_data, n_features = X.shape\n",
    "        assert n_data == len(y)\n",
    "        \n",
    "        perm = np.random.permutation(n_data)\n",
    "        n_train = int(n_data * perc)\n",
    "        train_mask = perm[:n_train]\n",
    "        valid_mask = perm[n_train:]\n",
    "        \n",
    "        assert (len(train_mask)+len(valid_mask)) == n_data\n",
    "        \n",
    "        train_data = X[train_mask]\n",
    "        train_target = y[train_mask]\n",
    "        valid_data = X[valid_mask]\n",
    "        valid_target = y[valid_mask]\n",
    "        assert (len(train_data)+len(valid_data)) == n_data\n",
    "        \n",
    "        self.Xt = train_data\n",
    "        self.yt = train_target\n",
    "        self.Xv = valid_data\n",
    "        self.yv = valid_target\n",
    "        \n",
    "    def get_train(self):\n",
    "        return self.Xt, self.yt\n",
    "    \n",
    "    def get_valid(self):\n",
    "        return self.Xv, self.yv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_clusters(y, clust_labels, img_threshold=15):\n",
    "    #checks input\n",
    "    if y.ndim != 1: \n",
    "        raise Exception(2)\n",
    "    if len(y) != len(clust_labels):\n",
    "        raise Exception(4)\n",
    "        \n",
    "    #build histogram of categories (how many point for each cat)\n",
    "    cats = {}\n",
    "    for i in y:\n",
    "        cats[i] = cats.get(i, 0) + 1\n",
    "    n_cats = len(cats)\n",
    "    \n",
    "    #build histogram of clusters (how many point in each cluster)\n",
    "    clusters = {}\n",
    "    for i in clust_labels:\n",
    "        clusters[i] = clusters.get(i, 0) + 1\n",
    "    n_clusters = len(clusters)\n",
    "        \n",
    "    #create mapping from categories to index (to easily store data)\n",
    "    #done because we assume y's values can be different from range(n_categories)\n",
    "    #cat_list useful to quickly go back (header of result matrix)\n",
    "    cat_map = {}\n",
    "    cat_list = []\n",
    "    for i, cat in enumerate(cats):\n",
    "        cat_map[cat] = i\n",
    "        cat_list.append(cat)\n",
    "    \n",
    "    #for each cluster, computes proportion of point belonging to each category\n",
    "    result = np.zeros((n_clusters, n_cats))\n",
    "    tot_per_clust = np.zeros((n_clusters,1), dtype=int)\n",
    "    for i, clust in enumerate(clusters):\n",
    "        labels = y[clust_labels == clust]\n",
    "        tot_per_clust[i] = clusters[clust]\n",
    "        for cat in labels:\n",
    "            result[i,cat_map[cat]] += 1\n",
    "            \n",
    "    #to compute percentage of category points\n",
    "    perc_cat = []\n",
    "    for clust in range(len(result)):\n",
    "        i_max = np.argmax(result[clust,:])\n",
    "        tot = cats[cat_list[i_max]]\n",
    "        perc_cat.append(result[clust, i_max] / tot * 100)\n",
    "    \n",
    "    #express each value as a proportion (normalization)\n",
    "    result = result / tot_per_clust * 100\n",
    "    \n",
    "    #show graphical representation if matrix not too big\n",
    "    if n_cats < img_threshold and n_clusters < img_threshold:\n",
    "        plt.imshow(result)\n",
    "        \n",
    "    #for each cluster show the category that fits it best\n",
    "    for i,value in enumerate(np.argmax(result, axis=1)):\n",
    "        #frequency of category: number of datapoint of a specific category belonging to that cluster\n",
    "        #over the number of points in the cluster (variety within cluster)\n",
    "        #category clustering: number of datapoint of a specific category belonging to that cluster,\n",
    "        #over the total number of points of that category\n",
    "        print('cluster: %s --> top category: %s, frequency of category (variety within cluster): %.2f%%, category clustering: %.2f%%'\\\n",
    "              % (i, cat_list[value], result[i, value], perc_cat[i]))\n",
    "    score = np.sum(np.max(result, axis=1))/n_clusters\n",
    "    #maybe it's best to weight the score by the category clustering index (see k-means example below)\n",
    "    print(\"Overall score (doesn't consider category clustering): %.2f%%\"%(score))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize(df, column):\n",
    "    if not isinstance(column, (str, int)):\n",
    "        raise Exception(1)\n",
    "    #returns a copy of the standardized column\n",
    "    c = df[column].copy()\n",
    "    mean = c.mean()\n",
    "    sd = c.std()\n",
    "    return (c - mean) / sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_std(df, columns):\n",
    "    if not isinstance(columns, str):\n",
    "        if len(columns) == 0:\n",
    "            raise Exception('nto enough columns')\n",
    "    else:\n",
    "        raise Exception('must be an array or list')\n",
    "    #returns a new dataframe with standardized columns\n",
    "    new_df = pd.DataFrame()\n",
    "    for column in columns:\n",
    "        temp = standardize(df, column)\n",
    "        new_df[column] = temp\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means on traffic\n",
    "Just an exploratory study, let's see what we get..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster: 0 --> top category: V-Bag, frequency of category (variety within cluster): 39.88%, category clustering: 17.57%\n",
      "cluster: 1 --> top category: V-Bag, frequency of category (variety within cluster): 36.54%, category clustering: 40.00%\n",
      "cluster: 2 --> top category: V-Bag, frequency of category (variety within cluster): 35.88%, category clustering: 29.19%\n",
      "cluster: 3 --> top category: V-Bag, frequency of category (variety within cluster): 37.40%, category clustering: 13.24%\n",
      "Overall score (doesn't consider category clustering): 37.43%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD8CAYAAACPd+p5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9CVDMX0DDQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13326eb3c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = df_clean[traffic_columns]\n",
    "y = df_clean['Product']\n",
    "\n",
    "km = KMeans(n_clusters=4, init='k-means++', n_init=10, n_jobs=4)\n",
    "km.fit(X)\n",
    "score = check_clusters(y=y, clust_labels=km.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we try the same but with standardized columns, see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster: 0 --> top category: V-Bag, frequency of category (variety within cluster): 36.57%, category clustering: 32.03%\n",
      "cluster: 1 --> top category: V-Bag, frequency of category (variety within cluster): 36.75%, category clustering: 58.65%\n",
      "cluster: 2 --> top category: V-Bag, frequency of category (variety within cluster): 40.72%, category clustering: 9.19%\n",
      "cluster: 3 --> top category: V-Pet, frequency of category (variety within cluster): 50.00%, category clustering: 0.31%\n",
      "Overall score (doesn't consider category clustering): 41.01%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQoAAAD8CAYAAACPd+p5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n354AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13326e8b780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_std = batch_std(df_clean, traffic_columns)\n",
    "y = df_clean['Product']\n",
    "\n",
    "km = KMeans(n_clusters=4, init='k-means++', n_init=10, n_jobs=4)\n",
    "km.fit(X_std)\n",
    "score = check_clusters(y=y, clust_labels=km.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to have improved. Still the clusters seem to separate pretty poorly. Let's see the optimal value of k based on our previous score (using standardized data which seem to make more sense). We set the same seed each time so that the results are comparable and not influenced by different initial centroid allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster: 0 --> top category: V-Bag, frequency of category (variety within cluster): 36.43%, category clustering: 32.84%\n",
      "cluster: 1 --> top category: V-Bag, frequency of category (variety within cluster): 37.28%, category clustering: 67.16%\n",
      "Overall score (doesn't consider category clustering): 36.86%\n",
      "cluster: 0 --> top category: V-Bag, frequency of category (variety within cluster): 37.20%, category clustering: 31.62%\n",
      "cluster: 1 --> top category: V-Bag, frequency of category (variety within cluster): 37.16%, category clustering: 56.89%\n",
      "cluster: 2 --> top category: V-Bag, frequency of category (variety within cluster): 35.71%, category clustering: 11.49%\n",
      "Overall score (doesn't consider category clustering): 36.69%\n",
      "cluster: 0 --> top category: V-Bag, frequency of category (variety within cluster): 36.94%, category clustering: 30.00%\n",
      "cluster: 1 --> top category: V-Bag, frequency of category (variety within cluster): 36.62%, category clustering: 53.65%\n",
      "cluster: 2 --> top category: V-Bag, frequency of category (variety within cluster): 38.46%, category clustering: 16.22%\n",
      "cluster: 3 --> top category: V-Bag, frequency of category (variety within cluster): 33.33%, category clustering: 0.14%\n",
      "Overall score (doesn't consider category clustering): 36.34%\n",
      "cluster: 0 --> top category: V-Bag, frequency of category (variety within cluster): 36.59%, category clustering: 29.86%\n",
      "cluster: 1 --> top category: V-Bag, frequency of category (variety within cluster): 36.81%, category clustering: 58.65%\n",
      "cluster: 2 --> top category: V-Bag, frequency of category (variety within cluster): 37.33%, category clustering: 7.57%\n",
      "cluster: 3 --> top category: V-Bag, frequency of category (variety within cluster): 43.08%, category clustering: 3.78%\n",
      "cluster: 4 --> top category: V-Bag, frequency of category (variety within cluster): 50.00%, category clustering: 0.14%\n",
      "Overall score (doesn't consider category clustering): 40.76%\n",
      "cluster: 0 --> top category: V-Bag, frequency of category (variety within cluster): 36.79%, category clustering: 29.73%\n",
      "cluster: 1 --> top category: V-Bag, frequency of category (variety within cluster): 36.62%, category clustering: 55.68%\n",
      "cluster: 2 --> top category: V-Bag, frequency of category (variety within cluster): 39.58%, category clustering: 7.70%\n",
      "cluster: 3 --> top category: V-Bag, frequency of category (variety within cluster): 37.98%, category clustering: 6.62%\n",
      "cluster: 4 --> top category: V-Bag, frequency of category (variety within cluster): 33.33%, category clustering: 0.14%\n",
      "cluster: 5 --> top category: V-Bag, frequency of category (variety within cluster): 100.00%, category clustering: 0.14%\n",
      "Overall score (doesn't consider category clustering): 47.39%\n",
      "cluster: 0 --> top category: V-Bag, frequency of category (variety within cluster): 37.02%, category clustering: 29.86%\n",
      "cluster: 1 --> top category: V-Bag, frequency of category (variety within cluster): 36.60%, category clustering: 9.59%\n",
      "cluster: 2 --> top category: V-Bag, frequency of category (variety within cluster): 36.68%, category clustering: 56.35%\n",
      "cluster: 3 --> top category: V-Bag, frequency of category (variety within cluster): 39.06%, category clustering: 3.38%\n",
      "cluster: 4 --> top category: V-Bag, frequency of category (variety within cluster): 33.33%, category clustering: 0.14%\n",
      "cluster: 5 --> top category: V-Bag, frequency of category (variety within cluster): 100.00%, category clustering: 0.54%\n",
      "cluster: 6 --> top category: V-Bag, frequency of category (variety within cluster): 100.00%, category clustering: 0.14%\n",
      "Overall score (doesn't consider category clustering): 54.67%\n",
      "cluster: 0 --> top category: V-Bag, frequency of category (variety within cluster): 36.86%, category clustering: 29.19%\n",
      "cluster: 1 --> top category: V-Bag, frequency of category (variety within cluster): 36.99%, category clustering: 7.30%\n",
      "cluster: 2 --> top category: V-Bag, frequency of category (variety within cluster): 36.32%, category clustering: 53.11%\n",
      "cluster: 3 --> top category: V-Pet, frequency of category (variety within cluster): 39.04%, category clustering: 8.85%\n",
      "cluster: 4 --> top category: V-Bag, frequency of category (variety within cluster): 60.00%, category clustering: 0.81%\n",
      "cluster: 5 --> top category: V-Bag, frequency of category (variety within cluster): 47.62%, category clustering: 1.35%\n",
      "cluster: 6 --> top category: V-Bag, frequency of category (variety within cluster): 33.33%, category clustering: 0.14%\n",
      "cluster: 7 --> top category: V-Bag, frequency of category (variety within cluster): 83.33%, category clustering: 0.68%\n",
      "Overall score (doesn't consider category clustering): 46.69%\n",
      "cluster: 0 --> top category: V-Bag, frequency of category (variety within cluster): 36.94%, category clustering: 29.05%\n",
      "cluster: 1 --> top category: V-Pet, frequency of category (variety within cluster): 37.44%, category clustering: 12.73%\n",
      "cluster: 2 --> top category: V-Bag, frequency of category (variety within cluster): 36.88%, category clustering: 53.38%\n",
      "cluster: 3 --> top category: V-Bag, frequency of category (variety within cluster): 44.87%, category clustering: 4.73%\n",
      "cluster: 4 --> top category: V-Bag, frequency of category (variety within cluster): 37.50%, category clustering: 1.62%\n",
      "cluster: 5 --> top category: V-Pet, frequency of category (variety within cluster): 50.00%, category clustering: 0.62%\n",
      "cluster: 6 --> top category: V-Pet, frequency of category (variety within cluster): 50.00%, category clustering: 0.31%\n",
      "cluster: 7 --> top category: V-Bag, frequency of category (variety within cluster): 100.00%, category clustering: 0.54%\n",
      "cluster: 8 --> top category: V-Bag, frequency of category (variety within cluster): 50.00%, category clustering: 0.14%\n",
      "Overall score (doesn't consider category clustering): 49.29%\n",
      "cluster: 0 --> top category: V-Bag, frequency of category (variety within cluster): 37.07%, category clustering: 29.05%\n",
      "cluster: 1 --> top category: V-Pet, frequency of category (variety within cluster): 35.33%, category clustering: 8.23%\n",
      "cluster: 2 --> top category: V-Bag, frequency of category (variety within cluster): 36.17%, category clustering: 55.68%\n",
      "cluster: 3 --> top category: V-Bag, frequency of category (variety within cluster): 52.17%, category clustering: 1.62%\n",
      "cluster: 4 --> top category: V-Bag, frequency of category (variety within cluster): 60.00%, category clustering: 0.81%\n",
      "cluster: 5 --> top category: V-Bag, frequency of category (variety within cluster): 42.86%, category clustering: 3.65%\n",
      "cluster: 6 --> top category: V-Bag, frequency of category (variety within cluster): 41.67%, category clustering: 1.35%\n",
      "cluster: 7 --> top category: V-Pet, frequency of category (variety within cluster): 50.00%, category clustering: 0.31%\n",
      "cluster: 8 --> top category: V-Bag, frequency of category (variety within cluster): 83.33%, category clustering: 0.68%\n",
      "cluster: 9 --> top category: V-Bag, frequency of category (variety within cluster): 100.00%, category clustering: 0.14%\n",
      "Overall score (doesn't consider category clustering): 53.86%\n",
      "cluster: 0 --> top category: V-Bag, frequency of category (variety within cluster): 36.48%, category clustering: 29.73%\n",
      "cluster: 1 --> top category: V-Bag, frequency of category (variety within cluster): 36.37%, category clustering: 56.08%\n",
      "cluster: 2 --> top category: V-Bag, frequency of category (variety within cluster): 38.10%, category clustering: 6.49%\n",
      "cluster: 3 --> top category: V-Bag, frequency of category (variety within cluster): 60.00%, category clustering: 0.81%\n",
      "cluster: 4 --> top category: V-Pet, frequency of category (variety within cluster): 50.00%, category clustering: 0.93%\n",
      "cluster: 5 --> top category: V-Bag, frequency of category (variety within cluster): 43.75%, category clustering: 3.78%\n",
      "cluster: 6 --> top category: V-Bag, frequency of category (variety within cluster): 47.83%, category clustering: 1.49%\n",
      "cluster: 7 --> top category: V-Pet, frequency of category (variety within cluster): 66.67%, category clustering: 0.62%\n",
      "cluster: 8 --> top category: V-Bag, frequency of category (variety within cluster): 33.33%, category clustering: 0.14%\n",
      "cluster: 9 --> top category: V-Bag, frequency of category (variety within cluster): 54.55%, category clustering: 0.81%\n",
      "cluster: 10 --> top category: V-Bag, frequency of category (variety within cluster): 100.00%, category clustering: 0.14%\n",
      "Overall score (doesn't consider category clustering): 51.55%\n",
      "cluster: 0 --> top category: V-Bag, frequency of category (variety within cluster): 37.22%, category clustering: 29.32%\n",
      "cluster: 1 --> top category: V-Bag, frequency of category (variety within cluster): 33.87%, category clustering: 5.68%\n",
      "cluster: 2 --> top category: V-Bag, frequency of category (variety within cluster): 36.31%, category clustering: 52.16%\n",
      "cluster: 3 --> top category: V-Pet, frequency of category (variety within cluster): 41.30%, category clustering: 5.90%\n",
      "cluster: 4 --> top category: V-Bag, frequency of category (variety within cluster): 60.00%, category clustering: 0.81%\n",
      "cluster: 5 --> top category: V-Bag, frequency of category (variety within cluster): 43.55%, category clustering: 3.65%\n",
      "cluster: 6 --> top category: V-Bag, frequency of category (variety within cluster): 36.67%, category clustering: 1.49%\n",
      "cluster: 7 --> top category: V-Bag, frequency of category (variety within cluster): 45.00%, category clustering: 1.22%\n",
      "cluster: 8 --> top category: V-Pet, frequency of category (variety within cluster): 66.67%, category clustering: 0.62%\n",
      "cluster: 9 --> top category: V-Bag, frequency of category (variety within cluster): 33.33%, category clustering: 0.14%\n",
      "cluster: 10 --> top category: V-Bag, frequency of category (variety within cluster): 83.33%, category clustering: 0.68%\n",
      "cluster: 11 --> top category: V-Bag, frequency of category (variety within cluster): 100.00%, category clustering: 0.14%\n",
      "Overall score (doesn't consider category clustering): 51.44%\n",
      "cluster: 0 --> top category: V-Bag, frequency of category (variety within cluster): 37.44%, category clustering: 29.59%\n",
      "cluster: 1 --> top category: V-Bag, frequency of category (variety within cluster): 32.35%, category clustering: 4.46%\n",
      "cluster: 2 --> top category: V-Bag, frequency of category (variety within cluster): 36.41%, category clustering: 52.70%\n",
      "cluster: 3 --> top category: V-Pet, frequency of category (variety within cluster): 41.30%, category clustering: 5.90%\n",
      "cluster: 4 --> top category: V-Bag, frequency of category (variety within cluster): 60.00%, category clustering: 0.81%\n",
      "cluster: 5 --> top category: V-Pet, frequency of category (variety within cluster): 50.00%, category clustering: 0.93%\n",
      "cluster: 6 --> top category: V-Bag, frequency of category (variety within cluster): 43.55%, category clustering: 3.65%\n",
      "cluster: 7 --> top category: V-Bag, frequency of category (variety within cluster): 36.67%, category clustering: 1.49%\n",
      "cluster: 8 --> top category: V-Bag, frequency of category (variety within cluster): 45.00%, category clustering: 1.22%\n",
      "cluster: 9 --> top category: V-Pet, frequency of category (variety within cluster): 66.67%, category clustering: 0.62%\n",
      "cluster: 10 --> top category: V-Bag, frequency of category (variety within cluster): 33.33%, category clustering: 0.14%\n",
      "cluster: 11 --> top category: V-Bag, frequency of category (variety within cluster): 83.33%, category clustering: 0.68%\n",
      "cluster: 12 --> top category: V-Bag, frequency of category (variety within cluster): 100.00%, category clustering: 0.14%\n",
      "Overall score (doesn't consider category clustering): 51.24%\n",
      "cluster: 0 --> top category: V-Bag, frequency of category (variety within cluster): 38.74%, category clustering: 21.62%\n",
      "cluster: 1 --> top category: V-Pet, frequency of category (variety within cluster): 32.43%, category clustering: 3.73%\n",
      "cluster: 2 --> top category: V-Bag, frequency of category (variety within cluster): 35.68%, category clustering: 32.84%\n",
      "cluster: 3 --> top category: V-Bag, frequency of category (variety within cluster): 37.09%, category clustering: 30.27%\n",
      "cluster: 4 --> top category: V-Pet, frequency of category (variety within cluster): 42.05%, category clustering: 5.75%\n",
      "cluster: 5 --> top category: V-Bag, frequency of category (variety within cluster): 60.00%, category clustering: 0.81%\n",
      "cluster: 6 --> top category: V-Pet, frequency of category (variety within cluster): 50.00%, category clustering: 0.93%\n",
      "cluster: 7 --> top category: V-Bag, frequency of category (variety within cluster): 44.44%, category clustering: 3.24%\n",
      "cluster: 8 --> top category: V-Bag, frequency of category (variety within cluster): 36.67%, category clustering: 1.49%\n",
      "cluster: 9 --> top category: V-Bag, frequency of category (variety within cluster): 45.00%, category clustering: 1.22%\n",
      "cluster: 10 --> top category: V-Pet, frequency of category (variety within cluster): 66.67%, category clustering: 0.62%\n",
      "cluster: 11 --> top category: V-Bag, frequency of category (variety within cluster): 33.33%, category clustering: 0.14%\n",
      "cluster: 12 --> top category: V-Bag, frequency of category (variety within cluster): 100.00%, category clustering: 0.54%\n",
      "cluster: 13 --> top category: V-Bag, frequency of category (variety within cluster): 100.00%, category clustering: 0.14%\n",
      "Overall score (doesn't consider category clustering): 51.58%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGMAAAD8CAYAAABjCxoDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13321c80630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best = [0,0]\n",
    "np.random.seed(23453)\n",
    "for k in range(2, 15):\n",
    "    X_std = batch_std(df_clean, traffic_columns)\n",
    "    y = df_clean['Product']\n",
    "\n",
    "    km = KMeans(n_clusters=k, init='k-means++', n_init=10, n_jobs=4)\n",
    "    km.fit(X_std)\n",
    "    score = check_clusters(y=y, clust_labels=km.labels_)\n",
    "    if score > best[0]:\n",
    "        best = score, k\n",
    "print(best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
